{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this tutorial you will learn\n",
    "- how to create spark session\n",
    "- how to load data and check schema\n",
    "- how to check duplicate records\n",
    "- how to check missing values\n",
    "- how to extract date and time from datetime column\n",
    "- how to create new columns\n",
    "- how to group, aggregate, and filter data\n",
    "- how to make meaningful business insights\n",
    "\n",
    "Author: Ivy Wang  http://www.codewithivy.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/13 12:19:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, SQLContext\n",
    "spark = SparkSession.builder.appName('tutorial').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity| InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|12/1/10 8:26|     2.55|     17850|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|12/1/10 8:26|     3.39|     17850|United Kingdom|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|12/1/10 8:26|     2.75|     17850|United Kingdom|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|12/1/10 8:26|     3.39|     17850|United Kingdom|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|12/1/10 8:26|     3.39|     17850|United Kingdom|\n",
      "|   536365|    22752|SET 7 BABUSHKA NE...|       2|12/1/10 8:26|     7.65|     17850|United Kingdom|\n",
      "|   536365|    21730|GLASS STAR FROSTE...|       6|12/1/10 8:26|     4.25|     17850|United Kingdom|\n",
      "|   536366|    22633|HAND WARMER UNION...|       6|12/1/10 8:28|     1.85|     17850|United Kingdom|\n",
      "|   536366|    22632|HAND WARMER RED P...|       6|12/1/10 8:28|     1.85|     17850|United Kingdom|\n",
      "|   536367|    84879|ASSORTED COLOUR B...|      32|12/1/10 8:34|     1.69|     13047|United Kingdom|\n",
      "|   536367|    22745|POPPY'S PLAYHOUSE...|       6|12/1/10 8:34|      2.1|     13047|United Kingdom|\n",
      "|   536367|    22748|POPPY'S PLAYHOUSE...|       6|12/1/10 8:34|      2.1|     13047|United Kingdom|\n",
      "|   536367|    22749|FELTCRAFT PRINCES...|       8|12/1/10 8:34|     3.75|     13047|United Kingdom|\n",
      "|   536367|    22310|IVORY KNITTED MUG...|       6|12/1/10 8:34|     1.65|     13047|United Kingdom|\n",
      "|   536367|    84969|BOX OF 6 ASSORTED...|       6|12/1/10 8:34|     4.25|     13047|United Kingdom|\n",
      "|   536367|    22623|BOX OF VINTAGE JI...|       3|12/1/10 8:34|     4.95|     13047|United Kingdom|\n",
      "|   536367|    22622|BOX OF VINTAGE AL...|       2|12/1/10 8:34|     9.95|     13047|United Kingdom|\n",
      "|   536367|    21754|HOME BUILDING BLO...|       3|12/1/10 8:34|     5.95|     13047|United Kingdom|\n",
      "|   536367|    21755|LOVE BUILDING BLO...|       3|12/1/10 8:34|     5.95|     13047|United Kingdom|\n",
      "|   536367|    21777|RECIPE BOX WITH M...|       4|12/1/10 8:34|     7.95|     13047|United Kingdom|\n",
      "+---------+---------+--------------------+--------+------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read dataset and show the header\n",
    "df = spark.read.option('header','true').csv('/Users/ivyw/pyspark/Online_Retail.csv')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+------------+---------+----------+--------------+-----+\n",
      "|InvoiceNo|StockCode|         Description|Quantity| InvoiceDate|UnitPrice|CustomerID|       Country|Sales|\n",
      "+---------+---------+--------------------+--------+------------+---------+----------+--------------+-----+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|12/1/10 8:26|     2.55|     17850|United Kingdom| 15.3|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|12/1/10 8:26|     3.39|     17850|United Kingdom|20.34|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|12/1/10 8:26|     2.75|     17850|United Kingdom| 22.0|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|12/1/10 8:26|     3.39|     17850|United Kingdom|20.34|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|12/1/10 8:26|     3.39|     17850|United Kingdom|20.34|\n",
      "|   536365|    22752|SET 7 BABUSHKA NE...|       2|12/1/10 8:26|     7.65|     17850|United Kingdom| 15.3|\n",
      "|   536365|    21730|GLASS STAR FROSTE...|       6|12/1/10 8:26|     4.25|     17850|United Kingdom| 25.5|\n",
      "|   536366|    22633|HAND WARMER UNION...|       6|12/1/10 8:28|     1.85|     17850|United Kingdom| 11.1|\n",
      "|   536366|    22632|HAND WARMER RED P...|       6|12/1/10 8:28|     1.85|     17850|United Kingdom| 11.1|\n",
      "|   536367|    84879|ASSORTED COLOUR B...|      32|12/1/10 8:34|     1.69|     13047|United Kingdom|54.08|\n",
      "|   536367|    22745|POPPY'S PLAYHOUSE...|       6|12/1/10 8:34|      2.1|     13047|United Kingdom| 12.6|\n",
      "|   536367|    22748|POPPY'S PLAYHOUSE...|       6|12/1/10 8:34|      2.1|     13047|United Kingdom| 12.6|\n",
      "|   536367|    22749|FELTCRAFT PRINCES...|       8|12/1/10 8:34|     3.75|     13047|United Kingdom| 30.0|\n",
      "|   536367|    22310|IVORY KNITTED MUG...|       6|12/1/10 8:34|     1.65|     13047|United Kingdom|  9.9|\n",
      "|   536367|    84969|BOX OF 6 ASSORTED...|       6|12/1/10 8:34|     4.25|     13047|United Kingdom| 25.5|\n",
      "|   536367|    22623|BOX OF VINTAGE JI...|       3|12/1/10 8:34|     4.95|     13047|United Kingdom|14.85|\n",
      "|   536367|    22622|BOX OF VINTAGE AL...|       2|12/1/10 8:34|     9.95|     13047|United Kingdom| 19.9|\n",
      "|   536367|    21754|HOME BUILDING BLO...|       3|12/1/10 8:34|     5.95|     13047|United Kingdom|17.85|\n",
      "|   536367|    21755|LOVE BUILDING BLO...|       3|12/1/10 8:34|     5.95|     13047|United Kingdom|17.85|\n",
      "|   536367|    21777|RECIPE BOX WITH M...|       4|12/1/10 8:34|     7.95|     13047|United Kingdom| 31.8|\n",
      "+---------+---------+--------------------+--------+------------+---------+----------+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a new column names Sales. Sales = Quantity * UnitPrice\n",
    "\n",
    "from pyspark.sql.functions import col, round\n",
    "df = df.withColumn('Sales',col('Quantity') * col('UnitPrice'))\n",
    "df = df.withColumn('Sales', round(col('Sales'),2))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Start Analysis with SQL Statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register the dataset into sql \n",
    "df.createOrReplaceTempView(\"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:=============================>                             (4 + 4) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|counts_of_distinct_order|\n",
      "+------------------------+\n",
      "|                   25900|\n",
      "+------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# how many unique orders are there in the dataset?\n",
    "spark.sql('''\n",
    "     SELECT COUNT(DISTINCT InvoiceNo) as counts_of_distinct_order\n",
    "    FROM df\n",
    "    ''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:=======>                                                   (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|      total_sales|\n",
      "+-----------------+\n",
      "|9747747.929999102|\n",
      "+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# What is the total sales in the dataset?\n",
    "spark.sql('''\n",
    "    SELECT SUM(Sales) AS total_sales\n",
    "    FROM df\n",
    "          ''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|CustomerID|             sales|\n",
      "+----------+------------------+\n",
      "|      NULL| 1447682.120000056|\n",
      "|     14646| 279489.0199999999|\n",
      "|     18102|256438.48999999996|\n",
      "|     17450|187482.16999999998|\n",
      "|     14911|132572.62000000005|\n",
      "|     12415|123725.44999999998|\n",
      "|     14156|113384.14000000004|\n",
      "|     17511|          88125.38|\n",
      "|     16684| 65892.07999999999|\n",
      "|     13694|62653.100000000006|\n",
      "|     15311|59419.339999999975|\n",
      "+----------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# the top 10 most spends cutomers\n",
    "spark.sql('''\n",
    "          SELECT CustomerID, SUM(Sales) as sales\n",
    "          FROM df\n",
    "          GROUP BY CustomerID\n",
    "          ORDER BY Sales DESC\n",
    "          LIMIT 11\n",
    "          ''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+\n",
      "|summary|  InvoiceDate|\n",
      "+-------+-------------+\n",
      "|  count|       541909|\n",
      "|   mean|         NULL|\n",
      "| stddev|         NULL|\n",
      "|    min|1/10/11 10:04|\n",
      "|    max|  9/9/11 9:52|\n",
      "+-------+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# find the min and max of InvoiceDate\n",
    "df.describe('InvoiceDate').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+\n",
      "|        Country|number_of_customer|\n",
      "+---------------+------------------+\n",
      "| United Kingdom|              3950|\n",
      "|        Germany|                95|\n",
      "|         France|                87|\n",
      "|          Spain|                31|\n",
      "|        Belgium|                25|\n",
      "|    Switzerland|                21|\n",
      "|       Portugal|                19|\n",
      "|          Italy|                15|\n",
      "|        Finland|                12|\n",
      "|        Austria|                11|\n",
      "|         Norway|                10|\n",
      "|        Denmark|                 9|\n",
      "|Channel Islands|                 9|\n",
      "|      Australia|                 9|\n",
      "|    Netherlands|                 9|\n",
      "|         Sweden|                 8|\n",
      "|         Cyprus|                 8|\n",
      "|          Japan|                 8|\n",
      "|         Poland|                 6|\n",
      "|         Greece|                 4|\n",
      "+---------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# how many customers are there in each country?\n",
    "\n",
    "spark.sql('''\n",
    "          SELECT Country, COUNT(DISTINCT CustomerID) AS number_of_customer\n",
    "          FROM df\n",
    "          GROUP BY Country\n",
    "          ORDER BY number_of_customer DESC\n",
    "          ''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|CustomerId|number_of_purchase|\n",
      "+----------+------------------+\n",
      "|     12471|                49|\n",
      "|     12569|                35|\n",
      "|     12474|                30|\n",
      "|     12720|                29|\n",
      "|     12709|                26|\n",
      "|     12621|                23|\n",
      "|     12476|                20|\n",
      "|     12712|                17|\n",
      "|     12708|                16|\n",
      "|     12705|                14|\n",
      "|     12472|                13|\n",
      "|     12647|                13|\n",
      "|     12619|                13|\n",
      "|     12500|                13|\n",
      "|     12626|                13|\n",
      "|     12662|                12|\n",
      "|     12600|                11|\n",
      "|     12481|                11|\n",
      "|     12477|                 9|\n",
      "|     12473|                 9|\n",
      "+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# how many purchases made by each customer in Germany?\n",
    "\n",
    "spark.sql('''\n",
    "          SELECT CustomerId, COUNT(DISTINCT InvoiceNo) AS number_of_purchase\n",
    "          FROM df\n",
    "          WHERE Country = 'Germany'\n",
    "          GROUP BY CustomerId\n",
    "          ORDER BY number_of_purchase DESC\n",
    "          ''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|number_of_purchase|count|\n",
      "+------------------+-----+\n",
      "|                 1|   21|\n",
      "|                 2|   14|\n",
      "|                 3|   13|\n",
      "|                 4|   10|\n",
      "|                 5|    8|\n",
      "|                 6|    6|\n",
      "|                 7|    1|\n",
      "|                 8|    2|\n",
      "|                 9|    2|\n",
      "|                11|    2|\n",
      "|                12|    1|\n",
      "|                13|    5|\n",
      "|                14|    1|\n",
      "|                16|    1|\n",
      "|                17|    1|\n",
      "|                20|    1|\n",
      "|                23|    1|\n",
      "|                26|    1|\n",
      "|                29|    1|\n",
      "|                30|    1|\n",
      "+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# I want to know the purchase frequency in Germany\n",
    "\n",
    "tmp = spark.sql('''\n",
    "          SELECT CustomerId, COUNT(DISTINCT InvoiceNo) AS number_of_purchase\n",
    "          FROM df\n",
    "          WHERE Country = 'Germany'\n",
    "          GROUP BY CustomerId\n",
    "          ORDER BY number_of_purchase DESC\n",
    "          ''')\n",
    "#tmp.show()\n",
    "\n",
    "tmp.groupby('number_of_purchase').count().orderBy('number_of_purchase').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 40:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|number_of_purchase|count|\n",
      "+------------------+-----+\n",
      "|                 1| 1188|\n",
      "|                 2|  741|\n",
      "|                 3|  440|\n",
      "|                 4|  344|\n",
      "|                 5|  259|\n",
      "|                 6|  173|\n",
      "|                 7|  142|\n",
      "|                 8|  109|\n",
      "|                 9|   70|\n",
      "|                10|   73|\n",
      "|                11|   56|\n",
      "|                12|   46|\n",
      "|                13|   28|\n",
      "|                14|   38|\n",
      "|                15|   27|\n",
      "|                16|   25|\n",
      "|                17|   18|\n",
      "|                18|   18|\n",
      "|                19|   13|\n",
      "|                20|   12|\n",
      "+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# how about the situation in UK?\n",
    "# I want to know the purchase frequency in Germany\n",
    "\n",
    "tmp = spark.sql('''\n",
    "          SELECT CustomerId, COUNT(DISTINCT InvoiceNo) AS number_of_purchase\n",
    "          FROM df\n",
    "          WHERE Country = 'United Kingdom'\n",
    "          GROUP BY CustomerId\n",
    "          ORDER BY number_of_purchase DESC\n",
    "          ''')\n",
    "#tmp.show()\n",
    "\n",
    "tmp.groupby('number_of_purchase').count().orderBy('number_of_purchase').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+---------------+------------------+\n",
      "|        Country|     total_revenue|no_of_customers|sales_per_customer|\n",
      "+---------------+------------------+---------------+------------------+\n",
      "|           EIRE|263276.82000000007|              3| 87758.94000000002|\n",
      "|    Netherlands| 284661.5399999998|              9| 31629.05999999998|\n",
      "|      Australia|137077.26999999996|              9|15230.807777777773|\n",
      "|      Singapore|           9120.39|              1|           9120.39|\n",
      "|         Sweden|          36595.91|              8|        4574.48875|\n",
      "|          Japan|          35340.62|              8|         4417.5775|\n",
      "|        Iceland|            4310.0|              1|            4310.0|\n",
      "|         Norway|          35163.46|             10|          3516.346|\n",
      "|    Switzerland|          56385.35|             21|2685.0166666666664|\n",
      "|        Germany|221698.21000000017|             95|2333.6653684210546|\n",
      "|         France|          197403.9|             87|2269.0103448275863|\n",
      "|Channel Islands|          20086.29|              9|           2231.81|\n",
      "|        Denmark|18768.140000000003|              9| 2085.348888888889|\n",
      "| United Kingdom| 8187806.360000072|           3950|2072.8623696202712|\n",
      "|         Israel| 7907.820000000004|              4| 1976.955000000001|\n",
      "|        Finland|22326.740000000005|             12|1860.5616666666672|\n",
      "|          Spain|54774.579999999994|             31|1766.9219354838708|\n",
      "|        Lebanon|1693.8800000000003|              1|1693.8800000000003|\n",
      "|      Lithuania|           1661.06|              1|           1661.06|\n",
      "|        Belgium|          40910.96|             25|         1636.4384|\n",
      "+---------------+------------------+---------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# In each country, how about the spend per customer? \n",
    "spark.sql('''\n",
    "          SELECT Country, Sum(Sales) AS total_revenue, Count(DISTINCT CustomerID) AS no_of_customers,total_revenue/no_of_customers  AS sales_per_customer\n",
    "          FROM df\n",
    "          GROUP BY Country\n",
    "          ORDER BY sales_per_customer DESC\n",
    "          ''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 56:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+--------------------+------+\n",
      "|       Country|StockCode|         Description|counts|\n",
      "+--------------+---------+--------------------+------+\n",
      "|United Kingdom|   85123A|WHITE HANGING HEA...|  2204|\n",
      "|United Kingdom|   85099B|JUMBO BAG RED RET...|  2001|\n",
      "|United Kingdom|    22423|REGENCY CAKESTAND...|  1859|\n",
      "|United Kingdom|    47566|       PARTY BUNTING|  1634|\n",
      "|United Kingdom|    20725|LUNCH BAG RED RET...|  1460|\n",
      "|United Kingdom|    84879|ASSORTED COLOUR B...|  1416|\n",
      "|United Kingdom|    22720|SET OF 3 CAKE TIN...|  1316|\n",
      "|United Kingdom|    20727|LUNCH BAG  BLACK ...|  1292|\n",
      "|United Kingdom|    22457|NATURAL SLATE HEA...|  1250|\n",
      "|United Kingdom|    22469|HEART OF WICKER S...|  1199|\n",
      "|United Kingdom|    22386|JUMBO BAG PINK PO...|  1192|\n",
      "|United Kingdom|    21212|PACK OF 72 RETROS...|  1190|\n",
      "|United Kingdom|    22086|PAPER CHAIN KIT 5...|  1172|\n",
      "|United Kingdom|    21931|JUMBO STORAGE BAG...|  1160|\n",
      "|United Kingdom|    22411|JUMBO SHOPPER VIN...|  1159|\n",
      "|United Kingdom|    20728| LUNCH BAG CARS BLUE|  1112|\n",
      "|United Kingdom|    82482|WOODEN PICTURE FR...|  1103|\n",
      "|United Kingdom|    22666|RECIPE BOX PANTRY...|  1085|\n",
      "|United Kingdom|    22960|JAM MAKING SET WI...|  1078|\n",
      "|United Kingdom|    22383|LUNCH BAG SUKI DE...|  1072|\n",
      "+--------------+---------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# What is the best-selling product in each country?\n",
    "\n",
    "spark.sql('''\n",
    "          SELECT Country,StockCode,Description, Count(StockCode) AS counts\n",
    "          FROM df\n",
    "          GROUP BY Country,StockCode,Description\n",
    "          ORDER BY counts DESC\n",
    "          ''').show()\n",
    "\n",
    "# this statement shows the all products in each country with the order by the count of selling.\n",
    "# It is not yet what I want. Check the next statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 59:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+--------------------+------+\n",
      "|           Country|StockCode|         Description|counts|\n",
      "+------------------+---------+--------------------+------+\n",
      "|         Australia|    22720|SET OF 3 CAKE TIN...|    10|\n",
      "|           Austria|     POST|             POSTAGE|    14|\n",
      "|           Bahrain|   72802B|OCEAN SCENT CANDL...|     3|\n",
      "|           Belgium|     POST|             POSTAGE|    98|\n",
      "|            Brazil|    23051|RECYCLED ACAPULCO...|     1|\n",
      "|            Canada|    23192|BUNDLE OF 3 ALPHA...|     2|\n",
      "|   Channel Islands|    20725|LUNCH BAG RED RET...|     7|\n",
      "|            Cyprus|    22423|REGENCY CAKESTAND...|     8|\n",
      "|    Czech Republic|    22231|JIGSAW TREE WITH ...|     3|\n",
      "|           Denmark|     POST|             POSTAGE|    14|\n",
      "|              EIRE|       C2|            CARRIAGE|   108|\n",
      "|European Community|     POST|             POSTAGE|     3|\n",
      "|           Finland|     POST|             POSTAGE|    41|\n",
      "|            France|     POST|             POSTAGE|   311|\n",
      "|           Germany|     POST|             POSTAGE|   383|\n",
      "|            Greece|     POST|             POSTAGE|     4|\n",
      "|         Hong Kong|    22452|MEASURING TAPE BA...|     6|\n",
      "|           Iceland|    22375|AIRLINE BAG VINTA...|     6|\n",
      "|            Israel|    20719|WOODLAND CHARLOTT...|     4|\n",
      "|             Italy|     POST|             POSTAGE|    18|\n",
      "+------------------+---------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql('''SELECT Country, StockCode, Description, counts\n",
    "FROM (\n",
    "    SELECT Country, StockCode, Description, counts,\n",
    "           ROW_NUMBER() OVER (PARTITION BY Country ORDER BY counts DESC) AS row_num\n",
    "    FROM (\n",
    "        SELECT Country, StockCode, Description, COUNT(StockCode) AS Counts\n",
    "        FROM df\n",
    "        GROUP BY Country, StockCode, Description\n",
    "    ) temp\n",
    ") temp2\n",
    "WHERE row_num = 1\n",
    "          ''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the session and clean up\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
